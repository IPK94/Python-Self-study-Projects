{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Instagram with Python\n",
    "To scrap instagram i'll use the library \"instaloader\" which provides API for scrapping Instagram!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: instaloader in f:\\anaconda\\lib\\site-packages\n",
      "Requirement already satisfied: requests>=2.4 in f:\\anaconda\\lib\\site-packages (from instaloader)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in f:\\anaconda\\lib\\site-packages (from requests>=2.4->instaloader)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in f:\\anaconda\\lib\\site-packages (from requests>=2.4->instaloader)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in f:\\anaconda\\lib\\site-packages (from requests>=2.4->instaloader)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in f:\\anaconda\\lib\\site-packages (from requests>=2.4->instaloader)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 9.0.1, however version 21.0.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n",
      "F:\\anaconda\\lib\\site-packages\\win_unicode_console\\__init__.py:31: RuntimeWarning: sys.stdin.encoding == '1252', whereas sys.stdout.encoding == 'UTF-8', readline hook consumer may assume they are the same\n",
      "  readline_hook.enable(use_pyreadline=use_pyreadline)\n"
     ]
    }
   ],
   "source": [
    "# Importing the module\n",
    "!pip install instaloader\n",
    "import instaloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'instaloader.structures.Profile'>\n"
     ]
    }
   ],
   "source": [
    "# Creating an instance of Instaloader Class\n",
    "bot = instaloader.Instaloader()\n",
    "\n",
    "# Loading a profile from Instagram Account\n",
    "profile = instaloader.Profile.from_username(bot.context, \"cousinomic\")\n",
    "print(type(profile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Username:  cousinomic\n",
      "User ID:  45006524093\n",
      "Number of Posts:  25\n",
      "Followers:  21\n",
      "Following:  3\n",
      "Bio:  Here we are to make u guys laugh😂 and smile 😉\n",
      "YOUTUBE 👇\n",
      "Any External link:  https://youtu.be/bv-jLrlGfWk\n"
     ]
    }
   ],
   "source": [
    "# Printing Account Details\n",
    "\n",
    "print(\"Username: \", profile.username)\n",
    "print(\"User ID: \", profile.userid)\n",
    "print(\"Number of Posts: \", profile.mediacount)\n",
    "print(\"Followers: \", profile.followers)\n",
    "print(\"Following: \", profile.followees)\n",
    "print(\"Bio: \", profile.biography)\n",
    "print(\"Any External link: \", profile.external_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Login into Insta Account Using Python\n",
    "logging into the account for which I want to scrape the info is important because it will (allow) help me get the usernames, or every detail related to this particular account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Instagram password for cousinomic: ········\n"
     ]
    }
   ],
   "source": [
    "# Login with username and password\n",
    "bot.login(user=\"cousinomic\", passwd=\"cousinomics4\")\n",
    "\n",
    "# Interactive login\n",
    "bot.interactive_login(\"cousinomic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the names of Followerss:  ['princess_7456_ciya', 'pakka_gowdru_hudga_9632469475', 'najrulchaudhury', 'jaspreetkaur1925', 'radsaggarwal', 'puriharmeetkaur', 'sonualam9315561406', 'drjaspreetkaur1995', 'kalrameet', 'shuvajitbouri', 'biswambar9091', 'i_p1310', 'shivamverma1911', 'ravinder4632', 'guruashratrust', 'ranjeetk.72', 'rideswritesandpints', 'tajinderp1978', 'itsaman_dsingh', 'aj.anjan', 'preeet.daman']\n",
      "These are the names of Followings:  ['preeet.daman', 'i_p1310', 'aj.anjan']\n"
     ]
    }
   ],
   "source": [
    "# Now Retrieve the usernames of all followers\n",
    "followers = [follower.username for follower in profile.get_followers()]\n",
    "print(\"These are the names of Followerss: \", followers)\n",
    "\n",
    "\n",
    "# Retrieving the usernames of all followings\n",
    "followings = [followees.username for followees in profile.get_followees()]\n",
    "print(\"These are the names of Followings: \", followings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading Posts from Different Profile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cousinomic_1\\2021-03-06_14-51-35_UTC.jpg [Eezat hai 🤣😂😂 YOUTUBE : COUSI…] cousinomic_1\\2021-03-06_14-51-35_UTC.mp4 json \n",
      "cousinomic_2\\2021-02-26_19-29-54_UTC.jpg cousinomic_2\\2021-02-26_19-29-54_UTC.mp4 json \n",
      "cousinomic_3\\2021-02-21_09-50-58_UTC.jpg [\"A sister is both your mirror…] cousinomic_3\\2021-02-21_09-50-58_UTC.mp4 json \n",
      "cousinomic_4\\2021-02-20_19-34-14_UTC.jpg [Or Ye humarii pawrii ho rhii …] cousinomic_4\\2021-02-20_19-34-14_UTC.mp4 json \n",
      "cousinomic_5\\2021-02-18_11-45-26_UTC.jpg [Twinning since childhood 🔥✌️❤…] cousinomic_5\\2021-02-18_11-45-26_UTC.mp4 json \n",
      "cousinomic_6\\2021-02-13_20-18-26_UTC.jpg [New video is up on our YouTub…] cousinomic_6\\2021-02-13_20-18-26_UTC.mp4 json \n",
      "cousinomic_7\\2021-02-13_20-05-42_UTC.jpg [Hey fam !!!!! we are back wit…] json \n",
      "cousinomic_8\\2021-02-11_09-51-52_UTC.jpg [School he lagjan😑🤣🤣 YOUTUBE :…] cousinomic_8\\2021-02-11_09-51-52_UTC.mp4 json \n",
      "cousinomic_9\\2021-02-10_10-53-57_UTC.jpg [Merii pyari bhen✌️❤️😂😂 YouTub…] cousinomic_9\\2021-02-10_10-53-57_UTC.mp4 comments json \n",
      "cousinomic_10\\2021-02-04_12-27-50_UTC.jpg [Our new YOUTUBE video is up o…] cousinomic_10\\2021-02-04_12-27-50_UTC.mp4 json \n",
      "cousinomic_11\\2021-02-03_16-56-52_UTC.jpg [hey fam!!!! we are back with …] json \n",
      "cousinomic_12\\2021-01-29_15-45-46_UTC.jpg [Myself  Dr. Mashoor Gulati😂 .…] cousinomic_12\\2021-01-29_15-45-46_UTC.mp4 json \n",
      "cousinomic_13\\2021-01-28_10-51-30_UTC.jpg [Oh no no nooooooo🤣😂 .. Pov : …] cousinomic_13\\2021-01-28_10-51-30_UTC.mp4 json \n",
      "cousinomic_14\\2021-01-25_19-40-14_UTC.jpg [Fun time 🤣🤣 .. Youtube channe…] cousinomic_14\\2021-01-25_19-40-14_UTC.mp4 comments json \n",
      "cousinomic_15\\2021-01-25_14-10-07_UTC.jpg [hey fam !!! here is an quick …] cousinomic_15\\2021-01-25_14-10-07_UTC.mp4 json \n",
      "cousinomic_16\\2021-01-25_13-26-12_UTC.jpg [Whisper challenge video is up…] cousinomic_16\\2021-01-25_13-26-12_UTC.mp4 json \n",
      "cousinomic_17\\2021-01-25_13-07-53_UTC.jpg [Hey fam!!!!! we are back with…] json \n",
      "cousinomic_18\\2021-01-14_21-50-06_UTC.jpg [Hey fam !!! Our new video is …] json \n",
      "cousinomic_19\\2021-01-14_12-11-56_UTC_1.jpg cousinomic_19\\2021-01-14_12-11-56_UTC_2.jpg cousinomic_19\\2021-01-14_12-11-56_UTC_3.jpg cousinomic_19\\2021-01-14_12-11-56_UTC_4.jpg [Lohri🔥 . YOUTUBE :  COUSINOMI…] comments json \n",
      "cousinomic_20\\2021-01-12_14-03-04_UTC.jpg [Mtlb tusii hadd paar kr chleo…] cousinomic_20\\2021-01-12_14-03-04_UTC.mp4 json \n",
      "cousinomic_21\\2021-01-05_19-25-51_UTC.jpg [It's a love shot❤️✌️ . YOUTUB…] cousinomic_21\\2021-01-05_19-25-51_UTC.mp4 json \n",
      "cousinomic_22\\2021-01-05_13-15-53_UTC.jpg [Hey Fam ❤️!!!!!! We are back …] geo json \n",
      "cousinomic_23\\2021-01-02_16-56-33_UTC.jpg [This or that ✌️ Siblings edit…] cousinomic_23\\2021-01-02_16-56-33_UTC.mp4 json \n",
      "cousinomic_24\\2020-12-30_15-31-13_UTC.jpg [Hey Fam !!!!  What's up✌️.  H…] json \n",
      "cousinomic_25\\2020-12-29_05-45-34_UTC.jpg [We are  original and that's p…] json \n"
     ]
    }
   ],
   "source": [
    "# Loading a Different New Profile\n",
    "profile = instaloader.Profile.from_username(bot.context, \"cousinomic\")\n",
    "\n",
    "# get all posts in a generator object\n",
    "posts = profile.get_posts()\n",
    "\n",
    "# Iterate and Download them\n",
    "for index, post in enumerate(posts, 1):\n",
    "    bot.download_post(post, target=f\"{profile.username}_{index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<instaloader.nodeiterator.NodeIterator object at 0x000002D70276C908>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Retrieve all instagram tv posts\n",
    "instagramtv = profile.get_igtv_posts()\n",
    "print(instagramtv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#internship\\2021-03-13_15-01-26_UTC_profile_pic.jpg already exists\n",
      "Retrieving pictures with hashtag #internship...\n",
      "[ 1/10] #internship\\2021-03-30_10-47-36_UTC.jpg exists \n",
      "[ 2/10] #internship\\2021-03-30_10-47-08_UTC.jpg exists \n",
      "[ 3/10] #internship\\2021-03-30_10-41-51_UTC.jpg exists comments \n",
      "[ 4/10] #internship\\2021-03-30_10-41-29_UTC_1.jpg exists #internship\\2021-03-30_10-41-29_UTC_2.jpg exists #internship\\2021-03-30_10-41-29_UTC_3.jpg exists #internship\\2021-03-30_10-41-29_UTC_4.jpg exists \n",
      "[ 5/10] #internship\\2021-03-30_10-40-39_UTC_1.jpg exists #internship\\2021-03-30_10-40-39_UTC_2.jpg exists #internship\\2021-03-30_10-40-39_UTC_3.jpg exists \n",
      "[ 6/10] #internship\\2021-03-30_10-30-47_UTC_1.jpg exists #internship\\2021-03-30_10-30-47_UTC_2.jpg exists comments \n",
      "[ 7/10] #internship\\2021-03-30_10-30-45_UTC.jpg exists \n",
      "[ 8/10] #internship\\2021-03-30_10-30-41_UTC_1.jpg exists #internship\\2021-03-30_10-30-41_UTC_2.jpg exists #internship\\2021-03-30_10-30-41_UTC_3.jpg exists #internship\\2021-03-30_10-30-41_UTC_4.jpg exists #internship\\2021-03-30_10-30-41_UTC_5.jpg exists \n",
      "[ 9/10] #internship\\2021-03-30_10-29-37_UTC_1.jpg exists #internship\\2021-03-30_10-29-37_UTC_2.jpg exists #internship\\2021-03-30_10-29-37_UTC_3.jpg exists #internship\\2021-03-30_10-29-37_UTC_4.jpg exists #internship\\2021-03-30_10-29-37_UTC_5.jpg exists \n",
      "[10/10] #internship\\2021-03-30_10-26-02_UTC.jpg exists \n"
     ]
    }
   ],
   "source": [
    "# downloading data related to hashtag; max_count specifies no. of outputs u wish to get!\n",
    "# 2 ways! if u need anything related to hashtag use 1st way! \n",
    "# 1st way\n",
    "bot = instaloader.Instaloader()\n",
    "\n",
    "# 2nd Way works for when u need output of hashtag with posted only photos! \n",
    "bot = instaloader.Instaloader(download_videos=False, save_metadata=False, post_metadata_txt_pattern='')\n",
    "bot.download_hashtag(hashtag=\"internship\", max_count=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
